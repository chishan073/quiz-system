import os
from openai import OpenAI
import json
import time
from dotenv import load_dotenv  # â¬…ï¸ è®€å– .env æª”
from tqdm import tqdm  # âœ… åŠ å…¥é€²åº¦æ¢

# âœ… è¼‰å…¥ .env ä¸­çš„ API é‡‘é‘°
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ è«‹åœ¨ .env æª”ä¸­è¨­å®š OPENAI_API_KEY")
client = OpenAI(api_key=api_key)


# å„ªå…ˆè®€å–è£œéè§£æçš„ç‰ˆæœ¬
if os.path.exists("questions_with_explanations.json"):
    with open("questions_with_explanations.json", "r", encoding="utf-8") as f:
        questions = json.load(f)
        print("ğŸ“ å·²è®€å–å·²è£œä¸Šè§£æçš„é¡Œåº«è³‡æ–™ã€‚")
else:
    with open("questions_answers.json", "r", encoding="utf-8") as f:
        questions = json.load(f)
        print("ğŸ“„ å¾åŸå§‹é¡Œåº«è®€å–è³‡æ–™ã€‚")

# éŒ¯èª¤è¨˜éŒ„æª”åˆå§‹åŒ–ï¼ˆæ¯æ¬¡é‡è·‘æœƒæ¸…ç©ºï¼‰
with open("error_log.txt", "w", encoding="utf-8") as log_file:
    log_file.write("ğŸš¨ éŒ¯èª¤é¡Œç›®ç´€éŒ„\n\n")

batch_size = 5
total_questions = len(questions)

for i in range(0, total_questions, batch_size):
    batch = questions[i:i + batch_size]
    any_updated = False

    print(f"\nğŸ”„ è™•ç†ç¬¬ {i+1} åˆ° {i+len(batch)} é¡Œ...")

    # ä½¿ç”¨ tqdm åŒ…è£æ‰¹æ¬¡ä¸­çš„é¡Œç›®ï¼Œé¡¯ç¤ºé€²åº¦æ¢
    for item in tqdm(batch, desc="è™•ç†ä¸­", unit="é¡Œ"):
        if "explanation" not in item or not item["explanation"].strip():
            prompt = f"""
            è«‹é‡å°ä»¥ä¸‹é¸æ“‡é¡Œæä¾›è©³ç´°çš„è§£æï¼Œèªªæ˜ç‚ºä»€éº¼æ­£ç¢ºç­”æ¡ˆæ˜¯ {item["answer"]}ã€‚

            é¡Œç›®ï¼š
            {item["question_text"]}

            é¸é …ï¼š
            {json.dumps(item.get("options", {}), ensure_ascii=False, indent=2)}
            """
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½é†«å­¸è€ƒé¡Œè§£æå°ˆå®¶ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7
                )
                explanation = response.choices[0].message.content.strip()
                item["explanation"] = explanation
                any_updated = True
                time.sleep(20)  # æ¯é¡Œé–“éš” 20 ç§’
            except Exception as e:
                print(f"âŒ ç¬¬ {item['question_number']} é¡Œç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                item["explanation"] = "ç”¢ç”Ÿå¤±æ•—"
                # å¯«å…¥éŒ¯èª¤ log
                with open("error_log.txt", "a", encoding="utf-8") as log_file:
                    log_file.write(f"ç¬¬ {item['question_number']} é¡ŒéŒ¯èª¤ï¼š{str(e)}\n")

    
    # å„²å­˜é€²åº¦
    if any_updated:
        with open("questions_with_explanations.json", "w", encoding="utf-8") as f:
            json.dump(questions, f, ensure_ascii=False, indent=4)
        print(f"ğŸ’¾ å·²å„²å­˜è‡³ç¬¬ {i+len(batch)} é¡Œã€‚")
        print(f"ğŸ“Š å·²è™•ç† {i+len(batch)}/{total_questions} é¡Œ")
        print("ğŸ˜´ ç­‰å¾… 5 åˆ†é˜ä»¥é¿å…è§¸ç™¼ API é™åˆ¶...\n")
        print("âœ… æ‰¹æ¬¡å®Œæˆï¼Œç«‹å³é€²å…¥ä¸‹ä¸€æ‰¹ï¼ˆå› ç‚ºæˆ‘å€‘å·²ç¶“æ§åˆ¶æ¯é¡Œé–“éš”ï¼‰")

    else:
        print(f"â­ï¸ é€™ä¸€æ‰¹çš„é¡Œç›®éƒ½å·²æœ‰è§£æï¼Œç„¡éœ€å„²å­˜ã€‚")
        print("âš¡ å¿«é€Ÿè·³éç­‰å¾…ï¼Œå› ç‚ºé€™ä¸€æ‰¹æ²’æœ‰æ–°å¢è§£æã€‚\n")

print("ğŸ‰ æ‰€æœ‰é¡Œç›®è™•ç†å®Œæˆï¼")